#!/usr/bin/env python3
"""
Shannon è´Ÿè½½æµ‹è¯•å’Œå‹åŠ›æµ‹è¯•
æ¨¡æ‹ŸçœŸå®ç”¨æˆ·è´Ÿè½½ï¼Œæµ‹è¯•ç³»ç»Ÿåœ¨é«˜å¹¶å‘ä¸‹çš„è¡¨ç°
"""

import time
import argparse
import statistics
import json
import sys
import random
from typing import List, Dict, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, asdict
from datetime import datetime

try:
    import grpc
    from google.protobuf import struct_pb2
    sys.path.insert(0, './clients/python/src')
    from shannon.pb import orchestrator_pb2, orchestrator_pb2_grpc, common_pb2
    GRPC_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸  Warning: gRPC imports failed: {e}")
    GRPC_AVAILABLE = False


@dataclass
class RequestResult:
    """å•ä¸ªè¯·æ±‚çš„ç»“æœ"""
    timestamp: float
    duration: float
    success: bool
    status_code: str = ""
    error: str = ""
    request_type: str = "task"


class LoadTest:
    """è´Ÿè½½æµ‹è¯•å·¥å…·"""
    
    def __init__(self, endpoint="localhost:50052", api_key="test-key", use_simulation=False):
        self.endpoint = endpoint
        self.api_key = api_key
        self.use_simulation = use_simulation or not GRPC_AVAILABLE
        self.results: List[RequestResult] = []
        
    def _get_metadata(self):
        return [('x-api-key', self.api_key)]
    
    def _create_channel(self):
        """ä¸ºæ¯ä¸ªçº¿ç¨‹åˆ›å»ºç‹¬ç«‹çš„ gRPC channel"""
        if self.use_simulation:
            return None
        return grpc.insecure_channel(self.endpoint)
    
    def _send_request(self, user_id: int, request_num: int) -> RequestResult:
        """å‘é€å•ä¸ªè¯·æ±‚"""
        start = time.time()
        timestamp = start
        
        # Random query selection for realistic load
        queries = [
            "Calculate the factorial of 20",
            "Search for recent AI developments",
            "Write a Python function to sort a list",
            "Explain quantum computing in simple terms",
            "What's the weather like today?",
            "Debug this code: def foo(): return x + 1",
            "Summarize the latest tech news",
            "Create a TODO list for project planning",
        ]
        
        query = random.choice(queries)
        
        try:
            if self.use_simulation:
                # Simulate varying response times
                base_latency = 0.5
                variation = random.gauss(0, 0.15)  # æ­£æ€åˆ†å¸ƒå˜åŒ–
                latency = max(0.1, base_latency + variation)
                time.sleep(latency)
                
                # Simulate occasional failures (5% failure rate)
                success = random.random() > 0.05
                status = "completed" if success else "failed"
                error = "" if success else "Simulated timeout"
            else:
                channel = self._create_channel()
                client = orchestrator_pb2_grpc.OrchestratorServiceStub(channel)
                
                request = orchestrator_pb2.TaskRequest(
                    query=query,
                    user_id=f"load-test-user-{user_id}",
                    mode=common_pb2.EXECUTION_MODE_STANDARD,
                )
                
                response = client.SubmitTask(
                    request,
                    metadata=self._get_metadata(),
                    timeout=30.0
                )
                
                success = response.status == "completed"
                status = response.status
                error = ""
                
                if channel:
                    channel.close()
        
        except Exception as e:
            success = False
            status = "error"
            error = str(e)
        
        duration = time.time() - start
        
        return RequestResult(
            timestamp=timestamp,
            duration=duration,
            success=success,
            status_code=status,
            error=error
        )
    
    def run_constant_load(self, users: int, duration_seconds: int, requests_per_user: int = None):
        """æ’å®šè´Ÿè½½æµ‹è¯•"""
        print(f"\nğŸ“Š æ’å®šè´Ÿè½½æµ‹è¯•")
        print(f"   å¹¶å‘ç”¨æˆ·: {users}, æŒç»­æ—¶é—´: {duration_seconds}s")
        print("-" * 60)
        
        start_time = time.time()
        end_time = start_time + duration_seconds
        
        completed = 0
        with ThreadPoolExecutor(max_workers=users) as executor:
            futures = []
            user_requests = [0] * users
            
            while time.time() < end_time:
                # ä¸ºæ¯ä¸ªç”¨æˆ·æäº¤è¯·æ±‚
                for user_id in range(users):
                    if requests_per_user and user_requests[user_id] >= requests_per_user:
                        continue
                    
                    future = executor.submit(self._send_request, user_id, user_requests[user_id])
                    futures.append(future)
                    user_requests[user_id] += 1
                
                # æ”¶é›†å®Œæˆçš„è¯·æ±‚
                done_futures = [f for f in futures if f.done()]
                for future in done_futures:
                    try:
                        result = future.result()
                        self.results.append(result)
                        completed += 1
                        
                        if completed % 50 == 0:
                            elapsed = time.time() - start_time
                            rate = completed / elapsed
                            print(f"  å·²å®Œæˆ: {completed} è¯·æ±‚, é€Ÿç‡: {rate:.1f} req/s")
                    except Exception as e:
                        print(f"  âŒ è¯·æ±‚å¤±è´¥: {e}")
                    
                    futures.remove(future)
                
                time.sleep(0.1)  # é¿å…è¿‡åº¦è½®è¯¢
            
            # ç­‰å¾…å‰©ä½™è¯·æ±‚å®Œæˆ
            print("\n  ç­‰å¾…å‰©ä½™è¯·æ±‚å®Œæˆ...")
            for future in as_completed(futures):
                try:
                    result = future.result()
                    self.results.append(result)
                    completed += 1
                except Exception as e:
                    print(f"  âŒ è¯·æ±‚å¤±è´¥: {e}")
        
        actual_duration = time.time() - start_time
        print(f"\nâœ… æµ‹è¯•å®Œæˆ: {completed} è¯·æ±‚, å®é™…ç”¨æ—¶: {actual_duration:.1f}s")
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        successful = [r for r in self.results if r.success]
        failed = [r for r in self.results if not r.success]
        
        mean_latency = statistics.mean([r.duration for r in successful]) if successful else 0
        
        return {
            'total_requests': len(self.results),
            'successful_requests': len(successful),
            'failed_requests': len(failed),
            'mean_latency': mean_latency,
            'actual_duration': actual_duration,
        }
    
    def run_ramp_up_load(self, max_users: int, ramp_up_seconds: int, hold_seconds: int):
        """æ¸è¿›å¼è´Ÿè½½æµ‹è¯•"""
        print(f"\nğŸ“Š æ¸è¿›å¼è´Ÿè½½æµ‹è¯•")
        print(f"   æœ€å¤§ç”¨æˆ·: {max_users}, çˆ¬å¡æ—¶é—´: {ramp_up_seconds}s, ä¿æŒæ—¶é—´: {hold_seconds}s")
        print("-" * 60)
        
        start_time = time.time()
        completed = 0
        
        with ThreadPoolExecutor(max_workers=max_users) as executor:
            futures = []
            current_users = 0
            
            # Phase 1: Ramp up
            print("\n[Phase 1] é€æ­¥å¢åŠ è´Ÿè½½...")
            ramp_end = start_time + ramp_up_seconds
            
            while time.time() < ramp_end:
                elapsed = time.time() - start_time
                target_users = int((elapsed / ramp_up_seconds) * max_users)
                
                # å¢åŠ ç”¨æˆ·æ•°
                while current_users < target_users:
                    user_id = current_users
                    future = executor.submit(self._send_request, user_id, 0)
                    futures.append(future)
                    current_users += 1
                
                # æ”¶é›†ç»“æœ
                done_futures = [f for f in futures if f.done()]
                for future in done_futures:
                    try:
                        result = future.result()
                        self.results.append(result)
                        completed += 1
                    except:
                        pass
                    futures.remove(future)
                
                if completed > 0 and completed % 20 == 0:
                    print(f"  å½“å‰ç”¨æˆ·: {current_users}/{max_users}, å·²å®Œæˆ: {completed}")
                
                time.sleep(0.1)
            
            # Phase 2: Hold at max load
            print(f"\n[Phase 2] ä¿æŒæœ€å¤§è´Ÿè½½ {max_users} ç”¨æˆ·...")
            hold_end = time.time() + hold_seconds
            
            while time.time() < hold_end:
                # ä¸ºæ¯ä¸ªç”¨æˆ·æäº¤æ–°è¯·æ±‚
                for user_id in range(max_users):
                    future = executor.submit(self._send_request, user_id, completed)
                    futures.append(future)
                
                # æ”¶é›†ç»“æœ
                done_futures = [f for f in futures if f.done()]
                for future in done_futures:
                    try:
                        result = future.result()
                        self.results.append(result)
                        completed += 1
                    except:
                        pass
                    futures.remove(future)
                
                if completed % 50 == 0:
                    rate = len([r for r in self.results if r.timestamp > time.time() - 1]) / 1.0
                    print(f"  å·²å®Œæˆ: {completed}, å½“å‰é€Ÿç‡: {rate:.1f} req/s")
                
                time.sleep(0.5)
            
            # ç­‰å¾…å‰©ä½™è¯·æ±‚
            print("\n  ç­‰å¾…å‰©ä½™è¯·æ±‚å®Œæˆ...")
            for future in as_completed(futures):
                try:
                    result = future.result()
                    self.results.append(result)
                    completed += 1
                except:
                    pass
        
        total_duration = time.time() - start_time
        print(f"\nâœ… æµ‹è¯•å®Œæˆ: {completed} è¯·æ±‚, æ€»ç”¨æ—¶: {total_duration:.1f}s")
    
    def run_spike_test(self, normal_users: int, spike_users: int, duration: int):
        """å³°å€¼å†²å‡»æµ‹è¯•"""
        print(f"\nğŸ“Š å³°å€¼å†²å‡»æµ‹è¯•")
        print(f"   æ­£å¸¸è´Ÿè½½: {normal_users} ç”¨æˆ·, å³°å€¼è´Ÿè½½: {spike_users} ç”¨æˆ·")
        print("-" * 60)
        
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=spike_users) as executor:
            # Phase 1: Normal load
            print("\n[Phase 1] æ­£å¸¸è´Ÿè½½...")
            for _ in range(duration // 3):
                futures = [executor.submit(self._send_request, i, 0) for i in range(normal_users)]
                for future in as_completed(futures):
                    try:
                        self.results.append(future.result())
                    except:
                        pass
                time.sleep(1)
            
            # Phase 2: Spike
            print(f"\n[Phase 2] è´Ÿè½½å³°å€¼å†²å‡»! ({spike_users} ç”¨æˆ·)")
            spike_futures = [executor.submit(self._send_request, i, 0) for i in range(spike_users)]
            for future in as_completed(spike_futures):
                try:
                    self.results.append(future.result())
                except:
                    pass
            
            # Phase 3: Back to normal
            print("\n[Phase 3] æ¢å¤æ­£å¸¸è´Ÿè½½...")
            for _ in range(duration // 3):
                futures = [executor.submit(self._send_request, i, 0) for i in range(normal_users)]
                for future in as_completed(futures):
                    try:
                        self.results.append(future.result())
                    except:
                        pass
                time.sleep(1)
        
        total_duration = time.time() - start_time
        print(f"\nâœ… å³°å€¼æµ‹è¯•å®Œæˆ, æ€»ç”¨æ—¶: {total_duration:.1f}s")
        
        # è¿”å›å„é˜¶æ®µç»“æœ
        return {
            'baseline_phase': {'users': normal_users},
            'spike_phase': {'users': spike_users, 'duration': duration},
            'recovery_phase': {'users': normal_users},
            'total_duration': total_duration
        }
    
    def simulate_concurrent_users(self, num_users: int, actions_per_user: int):
        """æ¨¡æ‹Ÿå¹¶å‘ç”¨æˆ·æµ‹è¯•"""
        print(f"\nğŸ“Š å¹¶å‘ç”¨æˆ·æ¨¡æ‹Ÿæµ‹è¯•")
        print(f"   ç”¨æˆ·æ•°: {num_users}, æ¯ç”¨æˆ·æ“ä½œ: {actions_per_user}")
        print("-" * 60)
        
        completed = 0
        with ThreadPoolExecutor(max_workers=num_users) as executor:
            futures = []
            
            # ä¸ºæ¯ä¸ªç”¨æˆ·æäº¤æ“ä½œ
            for user_id in range(num_users):
                for action_num in range(actions_per_user):
                    future = executor.submit(self._send_request, user_id, action_num)
                    futures.append(future)
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(futures):
                try:
                    result = future.result()
                    self.results.append(result)
                    completed += 1
                except Exception as e:
                    print(f"  âŒ è¯·æ±‚å¤±è´¥: {e}")
        
        print(f"\nâœ… å¹¶å‘ç”¨æˆ·æµ‹è¯•å®Œæˆ: {completed} ä¸ªæ“ä½œ")
        return {
            'total_requests': completed,
            'total_users': num_users,
            'completed_users': num_users,  # åœ¨æ¨¡æ‹Ÿæ¨¡å¼ä¸‹éƒ½å®Œæˆ
            'actions_per_user': actions_per_user,
            'results': self.results
        }
    
    def run_endurance_test(self, rps: int, duration_minutes: float):
        """è€ä¹…æ€§æµ‹è¯•ï¼ˆé•¿æ—¶é—´è¿è¡Œï¼‰"""
        duration_seconds = int(duration_minutes * 60)
        print(f"\nğŸ“Š è€ä¹…æ€§æµ‹è¯•")
        print(f"   ç›®æ ‡é€Ÿç‡: {rps} req/s, æŒç»­æ—¶é—´: {duration_minutes} åˆ†é’Ÿ")
        print("-" * 60)
        
        # ä½¿ç”¨run_constant_load
        users = max(1, rps // 2)  # ä¼°ç®—å¹¶å‘ç”¨æˆ·æ•°
        requests_per_user = max(1, (rps * duration_seconds) // users)
        
        self.run_constant_load(users, duration_seconds, requests_per_user)
        print(f"\nâœ… è€ä¹…æ€§æµ‹è¯•å®Œæˆ")
        
        # è¿”å›è€ä¹…æ€§æµ‹è¯•ç‰¹å®šçš„ç»“æœæ ¼å¼
        return {
            'duration_minutes': duration_minutes,
            'target_rps': rps,
            'total_requests': len(self.results),
            'successful_requests': sum(1 for r in self.results if r.success),
            'error_rate': self.calculate_error_rate(self.results)
        }
    
    def run_stress_test(self, max_rps: int, step: int, step_duration: int):
        """å‹åŠ›æµ‹è¯• - é€æ­¥å¢åŠ è´Ÿè½½ç›´åˆ°å¤±è´¥"""
        print(f"\nğŸ“Š å‹åŠ›æµ‹è¯•")
        print(f"   æœ€å¤§RPS: {max_rps}, æ­¥é•¿: {step}, æ¯æ­¥æ—¶é•¿: {step_duration}s")
        print("-" * 60)
        
        current_rps = step
        stress_results = []
        
        while current_rps <= max_rps:
            print(f"\n[å‹åŠ›çº§åˆ« {current_rps} RPS]")
            self.results = []  # é‡ç½®ç»“æœ
            
            users = max(1, current_rps // 2)
            self.run_constant_load(users, step_duration, None)
            
            error_rate = self.calculate_error_rate(self.results)
            avg_latency = statistics.mean([r.duration for r in self.results if r.success]) if self.results else 0
            
            stress_results.append({
                'rps': current_rps,
                'error_rate': error_rate,
                'avg_latency': avg_latency,
                'total_requests': len(self.results)
            })
            
            print(f"  é”™è¯¯ç‡: {error_rate*100:.1f}%, å¹³å‡å»¶è¿Ÿ: {avg_latency*1000:.0f}ms")
            
            # å¦‚æœé”™è¯¯ç‡è¶…è¿‡10%ï¼Œåœæ­¢æµ‹è¯•
            if error_rate > 0.1:
                print(f"\nâš ï¸  è¾¾åˆ°ç³»ç»Ÿæé™ï¼ˆé”™è¯¯ç‡>10%ï¼‰ï¼Œåœæ­¢æµ‹è¯•")
                break
            
            current_rps += step
        
        print(f"\nâœ… å‹åŠ›æµ‹è¯•å®Œæˆ")
        return stress_results
    
    def calculate_error_rate(self, results: List) -> float:
        """è®¡ç®—é”™è¯¯ç‡"""
        if not results:
            return 0.0
        
        # å¤„ç†ä¸åŒç±»å‹çš„ç»“æœ
        if isinstance(results[0], dict):
            failed = sum(1 for r in results if not r.get('success', True))
        else:
            failed = sum(1 for r in results if not r.success)
        
        return failed / len(results)
    
    def calculate_percentiles(self, latencies: List[float]) -> Dict[str, float]:
        """è®¡ç®—å»¶è¿Ÿç™¾åˆ†ä½æ•°"""
        if not latencies:
            return {'p50': 0, 'p95': 0, 'p99': 0}
        
        sorted_latencies = sorted(latencies)
        
        # å¯¼å…¥safe_percentile
        import sys
        from pathlib import Path
        sys.path.insert(0, str(Path(__file__).parent))
        from config import safe_percentile
        
        return {
            'p50': safe_percentile(sorted_latencies, 0.50) or 0,
            'p95': safe_percentile(sorted_latencies, 0.95) or 0,
            'p99': safe_percentile(sorted_latencies, 0.99) or 0,
        }
    
    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        if not self.results:
            print("\nâš ï¸  æ— æµ‹è¯•ç»“æœ")
            return
        
        successful = [r for r in self.results if r.success]
        failed = [r for r in self.results if not r.success]
        
        durations = [r.duration for r in successful]
        
        print("\n" + "=" * 60)
        print("è´Ÿè½½æµ‹è¯•æ€»ç»“")
        print("=" * 60)
        
        print(f"\nè¯·æ±‚ç»Ÿè®¡:")
        print(f"  æ€»è¯·æ±‚æ•°: {len(self.results)}")
        print(f"  æˆåŠŸ: {len(successful)} ({len(successful)/len(self.results)*100:.1f}%)")
        print(f"  å¤±è´¥: {len(failed)} ({len(failed)/len(self.results)*100:.1f}%)")
        
        if durations:
            sorted_durations = sorted(durations)
            p50 = sorted_durations[len(sorted_durations) // 2]
            p90 = sorted_durations[int(len(sorted_durations) * 0.90)]
            p95 = sorted_durations[int(len(sorted_durations) * 0.95)]
            p99 = sorted_durations[min(int(len(sorted_durations) * 0.99), len(sorted_durations) - 1)]
            
            print(f"\nå“åº”æ—¶é—´:")
            print(f"  å¹³å‡: {statistics.mean(durations):.3f}s")
            print(f"  ä¸­ä½æ•°: {statistics.median(durations):.3f}s")
            print(f"  æœ€å°: {min(durations):.3f}s")
            print(f"  æœ€å¤§: {max(durations):.3f}s")
            print(f"\n  ç™¾åˆ†ä½æ•°:")
            print(f"    P50: {p50:.3f}s")
            print(f"    P90: {p90:.3f}s")
            print(f"    P95: {p95:.3f}s")
            print(f"    P99: {p99:.3f}s")
        
        # Calculate throughput over time
        if self.results:
            start = min(r.timestamp for r in self.results)
            end = max(r.timestamp + r.duration for r in self.results)
            total_time = end - start
            throughput = len(self.results) / total_time if total_time > 0 else 0
            
            print(f"\nååé‡:")
            print(f"  å¹³å‡: {throughput:.1f} req/s")
            print(f"  æµ‹è¯•æ—¶é•¿: {total_time:.1f}s")
        
        # Error analysis
        if failed:
            print(f"\né”™è¯¯åˆ†æ:")
            error_types = {}
            for r in failed:
                error_key = r.error[:50] if r.error else r.status_code
                error_types[error_key] = error_types.get(error_key, 0) + 1
            
            for error, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True)[:5]:
                print(f"  {error}: {count} æ¬¡")


def main():
    parser = argparse.ArgumentParser(description="Shannon è´Ÿè½½æµ‹è¯•")
    parser.add_argument("--test-type",
                        choices=["constant", "ramp", "spike"],
                        default="constant",
                        help="æµ‹è¯•ç±»å‹")
    parser.add_argument("--users", type=int, default=10,
                        help="å¹¶å‘ç”¨æˆ·æ•°")
    parser.add_argument("--duration", type=int, default=60,
                        help="æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰")
    parser.add_argument("--ramp-up", type=int, default=10,
                        help="æ¸è¿›æµ‹è¯•çš„çˆ¬å¡æ—¶é—´ï¼ˆç§’ï¼‰")
    parser.add_argument("--spike-users", type=int, default=100,
                        help="å³°å€¼æµ‹è¯•çš„å³°å€¼ç”¨æˆ·æ•°")
    parser.add_argument("--endpoint", default="localhost:50052",
                        help="gRPC ç«¯ç‚¹")
    parser.add_argument("--api-key", default="test-key",
                        help="API Key")
    parser.add_argument("--simulate", action="store_true",
                        help="æ¨¡æ‹Ÿæ¨¡å¼")
    parser.add_argument("--output", type=str,
                        help="JSON è¾“å‡ºæ–‡ä»¶")
    
    args = parser.parse_args()
    
    load_test = LoadTest(
        endpoint=args.endpoint,
        api_key=args.api_key,
        use_simulation=args.simulate
    )
    
    print("\n" + "=" * 60)
    print("Shannon è´Ÿè½½æµ‹è¯•")
    print("=" * 60)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æµ‹è¯•æ¨¡å¼: {args.test_type}")
    print(f"æ¨¡æ‹Ÿæ¨¡å¼: {'æ˜¯' if args.simulate else 'å¦'}")
    
    try:
        if args.test_type == "constant":
            load_test.run_constant_load(args.users, args.duration)
        elif args.test_type == "ramp":
            load_test.run_ramp_up_load(args.users, args.ramp_up, args.duration)
        elif args.test_type == "spike":
            load_test.run_spike_test(args.users // 2, args.spike_users, args.duration)
        
        load_test.print_summary()
        
        if args.output:
            results_dict = {
                "test_type": args.test_type,
                "config": vars(args),
                "results": [asdict(r) for r in load_test.results],
                "timestamp": datetime.now().isoformat()
            }
            with open(args.output, 'w') as f:
                json.dump(results_dict, f, indent=2)
            print(f"\nâœ… è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° {args.output}")
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•è¢«ä¸­æ–­")
        load_test.print_summary()


if __name__ == "__main__":
    main()

