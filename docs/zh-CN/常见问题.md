# Shannon 常见问题解答 (FAQ)

## 📋 目录

- [安装与配置](#安装与配置)
- [使用问题](#使用问题)
- [性能优化](#性能优化)
- [故障排除](#故障排除)
- [开发相关](#开发相关)

---

## 安装与配置

### Q1: 最低系统要求是什么？

**A:** Shannon 需要以下最低配置：
- **CPU**: 2 核心或更多
- **内存**: 4GB RAM（推荐 8GB）
- **存储**: 10GB 可用空间
- **操作系统**: 
  - Linux (Ubuntu 20.04+, Rocky Linux 8+)
  - macOS (Intel/Apple Silicon)
  - Windows 10/11 (通过 WSL2 或 Docker Desktop)
- **软件要求**:
  - Docker 20.10+
  - Docker Compose v2.0+

### Q2: 如何在 Windows 上运行 Shannon？

**A:** Windows 用户有两种方式：

**方式 1: 使用 Docker Desktop（推荐）**
```bash
# 1. 安装 Docker Desktop for Windows
# 2. 确保启用 WSL2 支持
# 3. 克隆项目到 WSL2 文件系统中
wsl
git clone https://github.com/Kocoro-lab/Shannon.git
cd Shannon
make setup
make dev
```

**方式 2: 使用 WSL2**
```bash
# 在 WSL2 Ubuntu 中操作
sudo apt update
sudo apt install docker.io docker-compose
# 然后按照标准 Linux 安装流程
```

### Q3: 支持哪些 LLM 提供商？

**A:** Shannon 支持以下 LLM 提供商：

| 提供商 | 支持状态 | 配置方式 |
|--------|---------|----------|
| OpenAI | ✅ 完全支持 | `OPENAI_API_KEY` |
| Anthropic (Claude) | ✅ 完全支持 | `ANTHROPIC_API_KEY` |
| Google (Gemini) | ✅ 完全支持 | `GOOGLE_API_KEY` |
| DeepSeek | ✅ 完全支持 | `DEEPSEEK_API_KEY` |
| Groq | ✅ 完全支持 | `GROQ_API_KEY` |
| Ollama | ✅ 本地部署 | 配置 `base_url` |
| 自定义兼容 API | ✅ 支持 | 配置 `provider_settings` |

### Q4: 如何配置自定义 LLM 端点？

**A:** 在 `config/models.yaml` 中添加：

```yaml
provider_settings:
  my_custom_llm:
    base_url: "https://api.example.com/v1"
    api_key_env: "MY_CUSTOM_API_KEY"
    timeout: 30
    max_retries: 3
```

然后在 `.env` 文件中设置：
```bash
MY_CUSTOM_API_KEY=your_api_key_here
```

---

## 使用问题

### Q5: 如何提交第一个 AI 任务？

**A:** 有多种方式提交任务：

**方式 1: 使用 Dashboard UI（推荐新手）**
```bash
# 访问 http://localhost:2111
# 在界面中输入任务并提交
```

**方式 2: REST API**
```bash
export GATEWAY_SKIP_AUTH=1  # 开发环境
curl -X POST http://localhost:8080/api/v1/tasks \
  -H "Content-Type: application/json" \
  -d '{
    "query": "分析这段文本的情感：Shannon 让 AI 代理开发变简单了！",
    "session_id": "demo-session"
  }'
```

**方式 3: Python SDK**
```python
from shannon import ShannonClient

client = ShannonClient(grpc_endpoint="localhost:50052")
result = client.submit_task("你好，Shannon！", user_id="demo")
print(result.status, result.result)
```

### Q6: 如何实现实时流式输出？

**A:** Shannon 支持三种流式方式：

**1. Server-Sent Events (SSE) - 浏览器友好**
```bash
curl -N "http://localhost:8081/stream/sse?workflow_id=YOUR_WORKFLOW_ID"
```

**2. WebSocket - 双向通信**
```bash
wscat -c "ws://localhost:8081/stream/ws?workflow_id=YOUR_WORKFLOW_ID"
```

**3. gRPC 流式**
```bash
grpcurl -plaintext \
  -d '{"workflowId":"YOUR_WORKFLOW_ID"}' \
  localhost:50052 shannon.orchestrator.StreamingService/StreamTaskExecution
```

### Q7: 如何控制 Token 成本？

**A:** Shannon 提供多层成本控制：

**1. 设置任务预算**
```json
{
  "query": "你的任务",
  "config": {
    "budget": {
      "max_tokens": 5000,
      "fallback_model": "gpt-4o-mini"
    }
  }
}
```

**2. 使用 OPA 策略限制**
```rego
# config/opa/policies/budget.rego
package shannon.budget

max_tokens = 10000 {
    input.team == "support"
}

max_tokens = 100000 {
    input.team == "research"
}
```

**3. 启用智能路由**
- Shannon 的学习路由器会自动选择性价比最高的模型
- 可节省 85-95% token 成本（内部测试）

### Q8: 如何实现多代理协作？

**A:** 使用工作流模板：

```yaml
# config/workflows/user/multi-agent-example.yaml
name: multi_agent_research
pattern: supervisor
agents:
  - id: researcher
    role: "研究专家"
    tools: ["web_search", "document_read"]
  - id: analyst
    role: "数据分析师"
    tools: ["python_execute", "chart_generate"]
  - id: writer
    role: "报告撰写"
    tools: ["markdown_format"]
coordination:
  strategy: sequential
  supervisor_model: "gpt-4o"
```

---

## 性能优化

### Q9: 如何提高响应速度？

**A:** 以下优化可显著提升性能：

**1. 启用响应缓存**
```yaml
# config/models.yaml
prompt_cache:
  enabled: true
  ttl_seconds: 3600
  backend: redis  # 或 memory
```

**2. 使用会话持久化**
```bash
# 相同 session_id 会重用上下文
curl -X POST http://localhost:8080/api/v1/tasks \
  -d '{"query": "继续上次的话题", "session_id": "user-123"}'
```

**3. 调整模型层级**
- 简单任务用 `gpt-4o-mini`
- 复杂任务用 `gpt-4o` 或 `claude-4-sonnet`

### Q10: 如何处理高并发？

**A:** Shannon 天生支持横向扩展：

**1. 增加服务实例**
```yaml
# docker-compose.yml
services:
  orchestrator:
    deploy:
      replicas: 3
  agent-core:
    deploy:
      replicas: 5
```

**2. 配置速率限制**
```yaml
# config/features.yaml
rate_limits:
  orchestrator:
    requests_per_minute: 60
    tokens_per_minute: 100000
```

**3. 使用 Redis 集群**
```bash
# 配置 Redis 哨兵或集群模式
REDIS_URL=redis-sentinel://sentinel1:26379,sentinel2:26379/mymaster
```

---

## 故障排除

### Q11: 服务启动失败怎么办？

**A:** 按以下步骤排查：

**1. 检查端口占用**
```bash
# Windows
netstat -ano | findstr "8080 50051 50052"

# Linux/Mac
lsof -i :8080 -i :50051 -i :50052
```

**2. 查看服务日志**
```bash
docker compose logs orchestrator
docker compose logs agent-core
docker compose logs llm-service
```

**3. 验证依赖服务**
```bash
# 检查数据库连接
docker compose exec postgres pg_isready
docker compose exec redis redis-cli ping
```

**4. 重置环境**
```bash
make clean
docker compose down -v
make setup
make dev
```

### Q12: Token 超出预算怎么办？

**A:** 可以通过以下方式控制：

**1. 查看使用情况**
```bash
grpcurl -plaintext \
  -d '{"sessionId":"YOUR_SESSION_ID"}' \
  localhost:50052 shannon.orchestrator.OrchestratorService/GetSessionContext
```

**2. 设置熔断器**
```json
{
  "config": {
    "budget": {
      "circuit_breaker": {
        "threshold": 0.8,
        "cooldown_seconds": 60
      }
    }
  }
}
```

**3. 启用自动降级**
- 当达到 80% 预算时，自动切换到更便宜的模型

### Q13: 如何调试工作流失败？

**A:** 使用 Shannon 的时光旅行调试：

**1. 导出失败的工作流**
```bash
./scripts/replay_workflow.sh export task-failed-123 debug.json
```

**2. 本地重放**
```bash
./scripts/replay_workflow.sh replay debug.json
```

**3. 检查 Temporal UI**
```bash
# 访问 http://localhost:8088
# 查看工作流执行历史
```

### Q14: WASI 沙箱中 Python 代码执行失败？

**A:** 常见问题和解决方案：

**问题 1: 网络请求被阻止**
```python
# ❌ 不支持网络操作
import urllib.request
urllib.request.urlopen('http://example.com')  # 会失败

# ✅ 使用 Shannon 提供的工具
# 让 LLM 调用 web_search 或 api_call 工具
```

**问题 2: 文件系统只读**
```python
# ❌ 不能写入文件系统
with open('/tmp/file.txt', 'w') as f:  # 会失败
    f.write('data')

# ✅ 使用会话存储
data = {'result': [1, 2, 3]}
print(data)  # 输出会被捕获
```

**问题 3: 缺少 Python 库**
```bash
# WASI 环境只包含标准库
# 如需特殊库，提交 Issue 请求添加
```

---

## 开发相关

### Q15: 如何添加自定义工具？

**A:** 有三种方式添加工具：

**方式 1: Python MCP 工具（推荐）**
```python
# python/llm-service/tools/my_tool.py
from mcp import Tool

class MyCustomTool(Tool):
    name = "my_custom_tool"
    description = "工具描述"
    
    async def execute(self, **kwargs):
        # 工具逻辑
        return {"result": "success"}
```

**方式 2: OpenAPI 集成**
```yaml
# 在任务中使用
{
  "tools": [{
    "type": "openapi",
    "spec_url": "https://api.example.com/openapi.json",
    "operations": ["getUser", "createOrder"]
  }]
}
```

**方式 3: Rust 原生工具**
```rust
// rust/agent-core/src/tools/my_tool.rs
pub async fn execute_my_tool(input: ToolInput) -> Result<ToolOutput> {
    // 高性能工具逻辑
}
```

详见：[添加自定义工具指南](../adding-custom-tools.md)

### Q16: 如何参与贡献？

**A:** 欢迎各种形式的贡献！

**1. 文档贡献（新手友好）**
- 翻译英文文档
- 补充使用案例
- 改进代码示例

**2. 代码贡献**
```bash
# Fork 项目
git clone https://github.com/YOUR_USERNAME/Shannon.git
cd Shannon

# 创建功能分支
git checkout -b feature/my-feature

# 开发并测试
make dev
make test
make lint

# 提交 PR
git push origin feature/my-feature
```

**3. 问题反馈**
- 报告 Bug：[提交 Issue](https://github.com/Kocoro-lab/Shannon/issues/new)
- 功能建议：[发起讨论](https://github.com/Kocoro-lab/Shannon/discussions)

详见：[贡献指南](../../CONTRIBUTING.md)

### Q17: 本地开发环境如何配置？

**A:** 两种开发方式：

**完整 Docker 环境（快速开始）**
```bash
make setup
make dev
make smoke  # 验证
```

**本地服务开发（高级）**
```bash
# 1. 启动依赖服务
docker compose up -d postgres redis qdrant temporal

# 2. 分别启动服务
# Terminal 1 - Orchestrator (Go)
cd go/orchestrator && go run ./cmd/server

# Terminal 2 - Agent Core (Rust)
cd rust/agent-core && cargo run

# Terminal 3 - LLM Service (Python)
cd python/llm-service && python -m uvicorn main:app --reload

# Terminal 4 - Gateway
cd go/gateway && go run ./cmd/server

# Terminal 5 - Dashboard
cd observability/dashboard && npm run dev
```

---

## 更多帮助

### 获取支持

- 📖 [完整文档](https://github.com/Kocoro-lab/Shannon/blob/main/README.md)
- 💬 [Discord 社区](https://discord.gg/NB7C2fMcQR)
- 🐛 [问题追踪](https://github.com/Kocoro-lab/Shannon/issues)
- 💡 [功能讨论](https://github.com/Kocoro-lab/Shannon/discussions)

### 有用的命令

```bash
# 查看所有可用命令
make help

# 健康检查
make smoke

# 查看日志
make logs

# 清理环境
make clean

# 运行测试
make test

# 代码检查
make lint
```

---

*最后更新：2025 年 1 月*

